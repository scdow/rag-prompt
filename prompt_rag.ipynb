{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "with open('脱敏.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "pprint(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442\n",
      "[{0: 7446}, {1: 2959}, {2: 4732}, {3: 9070}, {4: 5684}, {5: 4555}, {6: 10069}, {7: 2151}, {8: 6576}, {9: 445}, {10: 514}, {11: 2055}, {12: 2163}, {13: 208632}, {14: 13858}, {15: 3536}, {16: 3748}, {17: 3859}, {18: 5391}, {19: 1729}, {20: 3874}, {21: 2354}, {22: 1395}, {23: 2620}, {24: 3643}, {25: 12331}, {26: 6039}, {27: 2450}, {28: 3650}, {29: 517}, {30: 3713}, {31: 4336}, {32: 2037}, {33: 0}, {34: 5502}, {35: 3266}, {36: 5514}, {37: 2996}, {38: 12276}, {39: 17410}, {40: 122}, {41: 1126}, {42: 306}, {43: 2385}, {44: 3078}, {45: 4174}, {46: 7554}, {47: 10705}, {48: 5854}, {49: 6057}, {50: 4681}, {51: 18204}, {52: 2126}, {53: 2624}, {54: 5192}, {55: 2362}, {56: 890}, {57: 1972}, {58: 12266}, {59: 19796}, {60: 9970}, {61: 2394}, {62: 1088}, {63: 24238}, {64: 2467}, {65: 3906}, {66: 11577}, {67: 9364}, {68: 10092}, {69: 6880}, {70: 1246}, {71: 6143}, {72: 5212}, {73: 5210}, {74: 20952}, {75: 6799}, {76: 11912}, {77: 5098}, {78: 10826}, {79: 9248}, {80: 4178}, {81: 3780}, {82: 3802}, {83: 4828}, {84: 10198}, {85: 5742}, {86: 4116}, {87: 4200}, {88: 4610}, {89: 3848}, {90: 5354}, {91: 3320}, {92: 5236}, {93: 4532}, {94: 3630}, {95: 24702}, {96: 2626}, {97: 1772}, {98: 10250}, {99: 10055}, {100: 6008}, {101: 8370}, {102: 12329}, {103: 3646}, {104: 5048}, {105: 7052}, {106: 3352}, {107: 8632}, {108: 4092}, {109: 4606}, {110: 1111}, {111: 19179}, {112: 54392}, {113: 208632}, {114: 2924}, {115: 2308}, {116: 4561}, {117: 1402}, {118: 2395}, {119: 7278}, {120: 5488}, {121: 2110}, {122: 5030}, {123: 6097}, {124: 6318}, {125: 1934}, {126: 17786}, {127: 7842}, {128: 13788}, {129: 5496}, {130: 3128}, {131: 4800}, {132: 3040}, {133: 3579}, {134: 9497}, {135: 1772}, {136: 3536}, {137: 6716}, {138: 3370}, {139: 9224}, {140: 13088}, {141: 14418}, {142: 10492}, {143: 2115}, {144: 2530}, {145: 10398}, {146: 3278}, {147: 3468}, {148: 5338}, {149: 9116}, {150: 1922}, {151: 4317}, {152: 3044}, {153: 1040}, {154: 3420}, {155: 5800}, {156: 7074}, {157: 10495}, {158: 2134}, {159: 3696}, {160: 5788}, {161: 7236}, {162: 4663}, {163: 11884}, {164: 4470}, {165: 1408}, {166: 2688}, {167: 1244}, {168: 16424}, {169: 11742}, {170: 4840}, {171: 3186}, {172: 5398}, {173: 3460}, {174: 2884}, {175: 4223}, {176: 3270}, {177: 3576}, {178: 7620}, {179: 13658}, {180: 14472}, {181: 3922}, {182: 4680}, {183: 2290}, {184: 4328}, {185: 1890}, {186: 4464}, {187: 4570}, {188: 2405}, {189: 7190}, {190: 5602}, {191: 6626}, {192: 5496}, {193: 3912}, {194: 6346}, {195: 10262}, {196: 5918}, {197: 8854}, {198: 7250}, {199: 3126}, {200: 4934}, {201: 5696}, {202: 5846}, {203: 7952}, {204: 8210}, {205: 5928}, {206: 5425}, {207: 2442}, {208: 2089}, {209: 3647}, {210: 1100}, {211: 7440}, {212: 67648}, {213: 2035}, {214: 11096}, {215: 3604}, {216: 29329}, {217: 1694}, {218: 4886}, {219: 9712}, {220: 15596}, {221: 4176}, {222: 5302}, {223: 5574}, {224: 1289}, {225: 5720}, {226: 7986}, {227: 11786}, {228: 2560}, {229: 4676}, {230: 5586}, {231: 2136}, {232: 2972}, {233: 2750}, {234: 3418}, {235: 10826}, {236: 2920}, {237: 11302}, {238: 4324}, {239: 5282}, {240: 5578}, {241: 5446}, {242: 7236}, {243: 2402}, {244: 9898}, {245: 7428}, {246: 1036}, {247: 5060}, {248: 9090}, {249: 1668}, {250: 13194}, {251: 8266}, {252: 6812}, {253: 6546}, {254: 45641}, {255: 3899}, {256: 14408}, {257: 13940}, {258: 9228}, {259: 7144}, {260: 4438}, {261: 2476}, {262: 7320}, {263: 10304}, {264: 14352}, {265: 8876}, {266: 9028}, {267: 10692}, {268: 8296}, {269: 13014}, {270: 10108}, {271: 4344}, {272: 6960}, {273: 21205}, {274: 634}, {275: 4938}, {276: 11126}, {277: 7536}, {278: 1338}, {279: 1946}, {280: 1250}, {281: 1378}, {282: 2518}, {283: 6590}, {284: 5422}, {285: 11676}, {286: 11804}, {287: 5314}, {288: 2240}, {289: 9638}, {290: 6350}, {291: 4078}, {292: 9006}, {293: 7846}, {294: 11038}, {295: 5546}, {296: 2746}, {297: 3300}, {298: 1472}, {299: 11270}, {300: 5458}, {301: 1332}, {302: 3494}, {303: 12006}, {304: 638}, {305: 16984}, {306: 9978}, {307: 6087}, {308: 3556}, {309: 13422}, {310: 8332}, {311: 3870}, {312: 4560}, {313: 12886}, {314: 9544}, {315: 6492}, {316: 13166}, {317: 6666}, {318: 3738}, {319: 6432}, {320: 3228}, {321: 1344}, {322: 3903}, {323: 3510}, {324: 14570}, {325: 10496}, {326: 21557}, {327: 12484}, {328: 1286}, {329: 1802}, {330: 7852}, {331: 5756}, {332: 8216}, {333: 18758}, {334: 2442}, {335: 8936}, {336: 12292}, {337: 4890}, {338: 5258}, {339: 21086}, {340: 6746}, {341: 14352}, {342: 2342}, {343: 8802}, {344: 906}, {345: 55029}, {346: 14730}, {347: 8192}, {348: 8014}, {349: 9516}, {350: 1698}, {351: 16420}, {352: 10692}, {353: 1186}, {354: 11906}, {355: 11536}, {356: 8450}, {357: 5930}, {358: 990}, {359: 6932}, {360: 3958}, {361: 8642}, {362: 6668}, {363: 8778}, {364: 1162}, {365: 13862}, {366: 20858}, {367: 1490}, {368: 2946}, {369: 3404}, {370: 952}, {371: 6572}, {372: 4776}, {373: 2494}, {374: 1814}, {375: 3404}, {376: 8076}, {377: 4126}, {378: 19414}, {379: 18296}, {380: 4004}, {381: 408}, {382: 2466}, {383: 4428}, {384: 870}, {385: 3756}, {386: 6206}, {387: 4010}, {388: 3049}, {389: 17864}, {390: 3598}, {391: 11038}, {392: 4358}, {393: 11460}, {394: 8788}, {395: 2496}, {396: 24042}, {397: 5334}, {398: 3288}, {399: 8806}, {400: 6300}, {401: 838}, {402: 9310}, {403: 4134}, {404: 2242}, {405: 3382}, {406: 1006}, {407: 6558}, {408: 6712}, {409: 868}, {410: 7462}, {411: 3126}, {412: 718}, {413: 978}, {414: 10588}, {415: 6092}, {416: 3024}, {417: 2986}, {418: 5148}, {419: 9410}, {420: 2612}, {421: 2186}, {422: 1616}, {423: 10588}, {424: 21086}, {425: 39992}, {426: 6866}, {427: 2186}, {428: 3864}, {429: 5995}, {430: 5684}, {431: 4004}, {432: 704}, {433: 5877}, {434: 5112}, {435: 1956}, {436: 652}, {437: 553}, {438: 5337}, {439: 2082}, {440: 1233}, {441: 5891}]\n",
      "[{13: 208632}, {113: 208632}, {212: 67648}, {345: 55029}, {112: 54392}, {254: 45641}, {425: 39992}, {216: 29329}, {95: 24702}, {63: 24238}, {396: 24042}, {326: 21557}, {273: 21205}, {339: 21086}, {424: 21086}, {74: 20952}, {366: 20858}, {59: 19796}, {378: 19414}, {111: 19179}, {333: 18758}, {379: 18296}, {51: 18204}, {389: 17864}, {126: 17786}, {39: 17410}, {305: 16984}, {168: 16424}, {351: 16420}, {220: 15596}, {346: 14730}, {324: 14570}, {180: 14472}, {141: 14418}, {256: 14408}, {264: 14352}, {341: 14352}, {257: 13940}, {365: 13862}, {14: 13858}, {128: 13788}, {179: 13658}, {309: 13422}, {250: 13194}, {316: 13166}, {140: 13088}, {269: 13014}, {313: 12886}, {327: 12484}, {25: 12331}, {102: 12329}, {336: 12292}, {38: 12276}, {58: 12266}, {303: 12006}, {76: 11912}, {354: 11906}, {163: 11884}, {286: 11804}, {227: 11786}, {169: 11742}, {285: 11676}, {66: 11577}, {355: 11536}, {393: 11460}, {237: 11302}, {299: 11270}, {276: 11126}, {214: 11096}, {294: 11038}, {391: 11038}, {78: 10826}, {235: 10826}, {47: 10705}, {267: 10692}, {352: 10692}, {414: 10588}, {423: 10588}, {325: 10496}, {157: 10495}, {142: 10492}, {145: 10398}, {263: 10304}, {195: 10262}, {98: 10250}, {84: 10198}, {270: 10108}, {68: 10092}, {6: 10069}, {99: 10055}, {306: 9978}, {60: 9970}, {244: 9898}, {219: 9712}, {289: 9638}, {314: 9544}, {349: 9516}, {134: 9497}, {419: 9410}, {67: 9364}, {402: 9310}, {79: 9248}, {258: 9228}, {139: 9224}, {149: 9116}, {248: 9090}, {3: 9070}, {266: 9028}, {292: 9006}, {335: 8936}, {265: 8876}, {197: 8854}, {399: 8806}, {343: 8802}, {394: 8788}, {363: 8778}, {361: 8642}, {107: 8632}, {356: 8450}, {101: 8370}, {310: 8332}, {268: 8296}, {251: 8266}, {332: 8216}, {204: 8210}, {347: 8192}, {376: 8076}, {348: 8014}, {226: 7986}, {203: 7952}, {330: 7852}, {293: 7846}, {127: 7842}, {178: 7620}, {46: 7554}, {277: 7536}, {410: 7462}, {0: 7446}, {211: 7440}, {245: 7428}, {262: 7320}, {119: 7278}, {198: 7250}, {161: 7236}, {242: 7236}, {189: 7190}, {259: 7144}, {156: 7074}, {105: 7052}, {272: 6960}, {359: 6932}, {69: 6880}, {426: 6866}, {252: 6812}, {75: 6799}, {340: 6746}, {137: 6716}, {408: 6712}, {362: 6668}, {317: 6666}, {191: 6626}, {283: 6590}, {8: 6576}, {371: 6572}, {407: 6558}, {253: 6546}, {315: 6492}, {319: 6432}, {290: 6350}, {194: 6346}, {124: 6318}, {400: 6300}, {386: 6206}, {71: 6143}, {123: 6097}, {415: 6092}, {307: 6087}, {49: 6057}, {26: 6039}, {100: 6008}, {429: 5995}, {357: 5930}, {205: 5928}, {196: 5918}, {441: 5891}, {433: 5877}, {48: 5854}, {202: 5846}, {155: 5800}, {160: 5788}, {331: 5756}, {85: 5742}, {225: 5720}, {201: 5696}, {4: 5684}, {430: 5684}, {190: 5602}, {230: 5586}, {240: 5578}, {223: 5574}, {295: 5546}, {36: 5514}, {34: 5502}, {129: 5496}, {192: 5496}, {120: 5488}, {300: 5458}, {241: 5446}, {206: 5425}, {284: 5422}, {172: 5398}, {18: 5391}, {90: 5354}, {148: 5338}, {438: 5337}, {397: 5334}, {287: 5314}, {222: 5302}, {239: 5282}, {338: 5258}, {92: 5236}, {72: 5212}, {73: 5210}, {54: 5192}, {418: 5148}, {434: 5112}, {77: 5098}, {247: 5060}, {104: 5048}, {122: 5030}, {275: 4938}, {200: 4934}, {337: 4890}, {218: 4886}, {170: 4840}, {83: 4828}, {131: 4800}, {372: 4776}, {2: 4732}, {50: 4681}, {182: 4680}, {229: 4676}, {162: 4663}, {88: 4610}, {109: 4606}, {187: 4570}, {116: 4561}, {312: 4560}, {5: 4555}, {93: 4532}, {164: 4470}, {186: 4464}, {260: 4438}, {383: 4428}, {392: 4358}, {271: 4344}, {31: 4336}, {184: 4328}, {238: 4324}, {151: 4317}, {175: 4223}, {87: 4200}, {80: 4178}, {221: 4176}, {45: 4174}, {403: 4134}, {377: 4126}, {86: 4116}, {108: 4092}, {291: 4078}, {387: 4010}, {380: 4004}, {431: 4004}, {360: 3958}, {181: 3922}, {193: 3912}, {65: 3906}, {322: 3903}, {255: 3899}, {20: 3874}, {311: 3870}, {428: 3864}, {17: 3859}, {89: 3848}, {82: 3802}, {81: 3780}, {385: 3756}, {16: 3748}, {318: 3738}, {30: 3713}, {159: 3696}, {28: 3650}, {209: 3647}, {103: 3646}, {24: 3643}, {94: 3630}, {215: 3604}, {390: 3598}, {133: 3579}, {177: 3576}, {308: 3556}, {15: 3536}, {136: 3536}, {323: 3510}, {302: 3494}, {147: 3468}, {173: 3460}, {154: 3420}, {234: 3418}, {369: 3404}, {375: 3404}, {405: 3382}, {138: 3370}, {106: 3352}, {91: 3320}, {297: 3300}, {398: 3288}, {146: 3278}, {176: 3270}, {35: 3266}, {320: 3228}, {171: 3186}, {130: 3128}, {199: 3126}, {411: 3126}, {44: 3078}, {388: 3049}, {152: 3044}, {132: 3040}, {416: 3024}, {37: 2996}, {417: 2986}, {232: 2972}, {1: 2959}, {368: 2946}, {114: 2924}, {236: 2920}, {174: 2884}, {233: 2750}, {296: 2746}, {166: 2688}, {96: 2626}, {53: 2624}, {23: 2620}, {420: 2612}, {228: 2560}, {144: 2530}, {282: 2518}, {395: 2496}, {373: 2494}, {261: 2476}, {64: 2467}, {382: 2466}, {27: 2450}, {207: 2442}, {334: 2442}, {188: 2405}, {243: 2402}, {118: 2395}, {61: 2394}, {43: 2385}, {55: 2362}, {21: 2354}, {342: 2342}, {115: 2308}, {183: 2290}, {404: 2242}, {288: 2240}, {421: 2186}, {427: 2186}, {12: 2163}, {7: 2151}, {231: 2136}, {158: 2134}, {52: 2126}, {143: 2115}, {121: 2110}, {208: 2089}, {439: 2082}, {11: 2055}, {32: 2037}, {213: 2035}, {57: 1972}, {435: 1956}, {279: 1946}, {125: 1934}, {150: 1922}, {185: 1890}, {374: 1814}, {329: 1802}, {97: 1772}, {135: 1772}, {19: 1729}, {350: 1698}, {217: 1694}, {249: 1668}, {422: 1616}, {367: 1490}, {298: 1472}, {165: 1408}, {117: 1402}, {22: 1395}, {281: 1378}, {321: 1344}, {278: 1338}, {301: 1332}, {224: 1289}, {328: 1286}, {280: 1250}, {70: 1246}, {167: 1244}, {440: 1233}, {353: 1186}, {364: 1162}, {41: 1126}, {110: 1111}, {210: 1100}, {62: 1088}, {153: 1040}, {246: 1036}, {406: 1006}, {358: 990}, {413: 978}, {370: 952}, {344: 906}, {56: 890}, {384: 870}, {409: 868}, {401: 838}, {412: 718}, {432: 704}, {436: 652}, {304: 638}, {274: 634}, {437: 553}, {29: 517}, {10: 514}, {9: 445}, {381: 408}, {42: 306}, {40: 122}, {33: 0}]\n"
     ]
    }
   ],
   "source": [
    "# sort by text length\n",
    "\n",
    "# https://www.脱敏/\n",
    "print(len(data))   # 442\n",
    "\n",
    "content_len = [{i: len(subdict['content'])} for i,subdict in enumerate(data)]\n",
    "print(content_len)\n",
    "\n",
    "content_len_sorted = sorted(content_len, key=lambda x: list(x.values())[0], reverse=True)\n",
    "print(content_len_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('脱敏_13.json','w', encoding='utf-8') as file:\n",
    "#     json.dump(data[list(content_len_sorted[0].keys())[0]],file, ensure_ascii=False)\n",
    "\n",
    "with open('脱敏_113.json','w', encoding='utf-8') as file:   # selected\n",
    "    json.dump(data[list(content_len_sorted[1].keys())[0]],file, ensure_ascii=False)\n",
    "\n",
    "# with open('脱敏_212.json','w', encoding='utf-8') as file:\n",
    "#     json.dump(data[list(content_len_sorted[2].keys())[0]],file, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "file_path='脱敏_113.json'\n",
    "text = json.loads(Path(file_path).read_text(encoding='utf-8'))['content']\n",
    "print(text)\n",
    "print(type(text))\n",
    "print(len(text))\n",
    "\n",
    "\n",
    "\n",
    "# file_path = 'akb.json'\n",
    "# json_content = json.loads(Path(file_path).read_text(encoding='utf-8'))\n",
    "# text = json_content['content']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  split text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "\n",
    "#分割长文本\n",
    "def SplitText(text, chunk_size=500, chunk_overlap=50):\n",
    "    text_splitter = CharacterTextSplitter(separator=\".\", chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunks = text   # when text not been split\n",
    "chunks = SplitText(text)\n",
    "\n",
    "pprint(chunks)\n",
    "print(type(chunks))\n",
    "print(len(chunks))\n",
    "print(len(chunks[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AirbyteJSONLoader : Load local Airbyte json files.  \n",
    "DiffbotLoader : \tLoad Diffbot json file.  \n",
    "JSONLoader  \n",
    "TelegramChatApiLoader : Load Telegram chat json directory dump.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text splitter in langchain\n",
    "https://python.langchain.com/v0.2/docs/how_to/#text-splitters  \n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\n",
    "        \"\\n\\n\",\n",
    "        \"\\n\",\n",
    "        \" \",\n",
    "        \".\",\n",
    "        \",\",\n",
    "        \"\\u200b\",  # Zero-width space\n",
    "        \"\\uff0c\",  # Fullwidth comma\n",
    "        \"\\u3001\",  # Ideographic comma\n",
    "        \"\\uff0e\",  # Fullwidth full stop\n",
    "        \"\\u3002\",  # Ideographic full stop\n",
    "        \"\",\n",
    "    ],\n",
    "    # Existing args\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# connect to llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\Anaconda3\\envs\\pyProject\\lib\\site-packages\\langchain_core\\utils\\utils.py:161: UserWarning: WARNING! top_p is not default parameter.\n",
      "                top_p was transferred to model_kwargs.\n",
      "                Please confirm that top_p is what you intended.\n",
      "  warnings.warn(\n",
      "e:\\anaconda\\Anaconda3\\envs\\pyProject\\lib\\site-packages\\langchain_core\\utils\\utils.py:161: UserWarning: WARNING! frequency_penalty is not default parameter.\n",
      "                frequency_penalty was transferred to model_kwargs.\n",
      "                Please confirm that frequency_penalty is what you intended.\n",
      "  warnings.warn(\n",
      "e:\\anaconda\\Anaconda3\\envs\\pyProject\\lib\\site-packages\\langchain_core\\utils\\utils.py:161: UserWarning: WARNING! presence_penalty is not default parameter.\n",
      "                presence_penalty was transferred to model_kwargs.\n",
      "                Please confirm that presence_penalty is what you intended.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x00000297E5C103D0> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000297E5C11ED0> model_name='gpt-3.5-turbo-0125' temperature=0.06 model_kwargs={'top_p': 0.1, 'frequency_penalty': 0, 'presence_penalty': 0} openai_api_key=SecretStr('**********') openai_api_base='https://api.chatanywhere.tech/v1' openai_proxy=''\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "API_KEY= \"脱敏\"\n",
    "MODEL = \"gpt-3.5-turbo-0125\"\n",
    "BASE_URL = \"https://api.chatanywhere.tech/v1\"\n",
    "MAX_TOKENS =None  #4095\n",
    "MAX_RETRIES = 2\n",
    "TIMEOUT = None\n",
    "TEMP = 0.06  #2\n",
    "TOP_P = 0.1  #1\n",
    "FREQ_PENALTY = 0   #2\n",
    "PRESENCE_PENALTY = 0   #2\n",
    "\n",
    "# langchain支持设置 top_p, frequency_penalty, presence_penalty等参数吗？支持的。\n",
    "# Any param which is not explicitly supported will be passed directly to the openai.OpenAI.chat.completions.create(...)\n",
    "\n",
    "llm = ChatOpenAI(model=MODEL, api_key=API_KEY, base_url=BASE_URL, \n",
    "                 max_tokens=MAX_TOKENS, max_retries = MAX_RETRIES, timeout=TIMEOUT,\n",
    "                 temperature=TEMP, top_p=TOP_P, frequency_penalty=FREQ_PENALTY, presence_penalty=PRESENCE_PENALTY)\n",
    "\n",
    "print(llm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text embedding\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\", openai_api_key=API_KEY, openai_api_base=BASE_URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(494, 1536)\n"
     ]
    }
   ],
   "source": [
    "chunks_vector = embeddings.embed_documents(chunks)\n",
    "chunks_vector_array = np.array(chunks_vector)\n",
    "print(chunks_vector_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector store: save embeddings temporarily\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstore = Chroma.from_texts(texts=chunks, embedding=embeddings)\n",
    "vectorstore_faiss = FAISS.from_texts(texts=chunks, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据提问匹配文本 \n",
    "# query = \"Is this content related to 脱敏?\"\n",
    "query = \"summarize the context\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method1\n",
    "docs_similar = vectorstore.similarity_search(query, k=3)\n",
    "pprint(docs_similar)\n",
    "\n",
    "docs_similar_faiss = vectorstore_faiss.similarity_search(query, k=5)\n",
    "pprint(docs_similar_faiss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method2\n",
    "retriever = vectorstore.as_retriever(search_kwargs={'k':4})\n",
    "docs_retrieve = retriever.invoke(query)  # 无法控制number of result (docs_retrieve的长度)\n",
    "pprint(docs_retrieve)\n",
    "\n",
    "retriever_faiss = vectorstore_faiss.as_retriever(search_kwargs={'k':5})\n",
    "docs_retrieve_faiss = retriever_faiss.invoke(query)  # 无法控制number of result (docs_retrieve的长度)\n",
    "pprint(docs_retrieve_faiss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_retrieve[0].page_content\n",
    "\n",
    "docs_retrieve_faiss[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and generate using the relevant snippets of the text.\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "  (\"user\", \"\"\"You are an expert for 脱敏. Please identify the topic of the following content. Then use the following context to analyse Is 某人 a X派 or a X派, please mark the score according the rule that <X is 1, a little X is 0.5, X is 0, a little X is -0.5, X is -1>; The definition of X, Y, Z are a, b, c respectively.\n",
    "Context: {context} \n",
    "Format the output as JSON with keys: topic: <topic>, score:<mark>, reason:<reason>\"\"\"),\n",
    "])\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    format_docs = \".\".join(doc.page_content for doc in docs)\n",
    "    print(len(docs))\n",
    "    print(format_docs)\n",
    "    return format_docs\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "  result = rag_chain.invoke(\"脱敏 or 脱敏?\")\n",
    "  print(result)\n",
    "  print(cb)\n",
    "\n",
    "# query = \"Is this content related to Gaza?\"\n",
    "# query = \"summarize the context\"\n",
    "  \n",
    "rag_chain_faiss = (\n",
    "    {\"context\": retriever_faiss | format_docs}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "  result_faiss = rag_chain_faiss.invoke(\"脱敏 or 脱敏?\")\n",
    "  print(result_faiss)\n",
    "  print(cb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_parser, format the output\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"score\", description=\"mark the score\"),\n",
    "    ResponseSchema(\n",
    "        name=\"reason\",\n",
    "        description=\"reasons for score \",\n",
    "    ),\n",
    "]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructioins = output_parser.get_format_instructions()\n",
    "\n",
    "# 'user', 'ai', 'assistant', or 'system'\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "  (\"system\", \"\"\"脱敏...\n",
    "Context: {context} \n",
    "{format_instructioins}\n",
    "\"\"\"),\n",
    "])\n",
    "\n",
    "def format_docs(docs):\n",
    "    format_docs = \".\".join(doc.page_content for doc in docs)\n",
    "    print(len(docs))\n",
    "    # print(format_docs)\n",
    "    return format_docs\n",
    "context = format_docs(retriever.invoke('脱敏 or 脱敏?') )   # 根据提问匹配文本？\n",
    "message = prompt.format_messages(context = context, format_instructioins=format_instructioins)\n",
    "\n",
    "response = llm(message)\n",
    "\n",
    "output_dict = output_parser.parse(response.content)\n",
    "print(output_dict)\n",
    "print(type(output_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{\n",
    "\t\"name\": \"PermissionDeniedError\",\n",
    "\t\"message\": \"Error code: 403 - {'error': {'message': '免费API限制模型输入token小于4096，如有更多需求，请访问 https://buyca.shop 购买付费API。The number of prompt tokens for free accounts is limited to 4096. If you have additional requirements, please visit https://buyca.shop to purchase a premium key.', 'type': 'chatanywhere_error', 'param': None, 'code': '403 FORBIDDEN'}}\",\n",
    "\t\"stack\": \"---------------------------------------------------------------------------\n",
    "PermissionDeniedError                     Traceback (most recent call last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提问参数\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo-0125\",\n",
    "  messages=[],\n",
    "  temperature=0.17,   #2\n",
    "  max_tokens=256,  #4095\n",
    "  top_p=0.88,  #1\n",
    "  frequency_penalty=0.1,   #2\n",
    "  presence_penalty=0.11,   #2\n",
    "  tools=[\n",
    "    {\n",
    "      \"type\": \"function\",\n",
    "      \"function\": {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Determine weather in my location\",\n",
    "        \"parameters\": {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {\n",
    "            \"location\": {\n",
    "              \"type\": \"string\",\n",
    "              \"description\": \"The city and state e.g. San Francisco, CA\"\n",
    "            },\n",
    "            \"unit\": {\n",
    "              \"type\": \"string\",\n",
    "              \"enum\": [\n",
    "                \"c\",\n",
    "                \"f\"\n",
    "              ]\n",
    "            }\n",
    "          },\n",
    "          \"required\": [\n",
    "            \"location\"\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  stop=[\"end.\", \"regards\"]  #4个\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
